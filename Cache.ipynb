{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c189bfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo\n",
      "  Downloading pymongo-4.3.3-cp39-cp39-win_amd64.whl (382 kB)\n",
      "Collecting dnspython<3.0.0,>=1.16.0\n",
      "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
      "Installing collected packages: dnspython, pymongo\n",
      "Successfully installed dnspython-2.3.0 pymongo-4.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement heapq (from versions: none)\n",
      "ERROR: No matching distribution found for heapq\n"
     ]
    }
   ],
   "source": [
    "%pip install pymongo\n",
    "%pip install heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26651576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pymongo import MongoClient\n",
    "from heapq import heapify, heappush, heappop\n",
    "import pymongo\n",
    "import time\n",
    "from mysql.connector import (connection)\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "867b1c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectCache:\n",
    "    \n",
    "    def __init__(self, database):\n",
    "        self.cache = {}                                      #Cache\n",
    "        self.minheap = []                                    #Minheap\n",
    "        self.cache_limit_value = 200                         #The cache will be set up to only hold 200 tweets\n",
    "        self.db = MongoClient(database)[\"my_final_database\"]\n",
    "        self.tweets = self.db[\"tweets\"]\n",
    "        ktdm = list(self.db[\"keywords\"].find())              #Holds all keywords and ids associated\n",
    "        htdm = list(self.db[\"hashtags\"].find())\n",
    "        self.keyword_tdm = dict((x['_id'], x['tweets']) for x in ktdm)\n",
    "        self.hashtag_tdm = dict((x['_id'], x['tweets']) for x in htdm)              #Holds all hashtags and ids associated\n",
    "        self.total_searches_kept_in_cache = 3      \n",
    "        self.recent_keyword_searches_cache = {}                      \n",
    "        self.recent_hashtag_searches_cache = {}\n",
    "        self.recent_keyword_searches = []\n",
    "        self.recent_hashtag_searches = []\n",
    "        self.connection1 = mysql.connector.connect(host=\"localhost\", user=\"root\", password=\"gXt,:RsU#U-ws:3\",database=\"new_database\")\n",
    "        self.users_through_tweets_cache = {}\n",
    "        self.users_through_tweets_list = []\n",
    "        \n",
    "    def __contains__(self, key):\n",
    "        \n",
    "        return key in self.cache\n",
    "    \n",
    "    def current_cache_size(self):\n",
    "        \n",
    "        return len(self.cache)\n",
    "    \n",
    "    def initial_population(self):\n",
    "        \n",
    "        #Read every tweet in collection and attempt to add them one by one to cache\n",
    "        for i in self.tweets:\n",
    "            add_update(i[\"id\"], i)\n",
    "           \n",
    "    def add_update(self, key, value):\n",
    "        \n",
    "        #Add a section that first checks if the current key's relevance value is greater \n",
    "        #than the least relevant term in the cache\n",
    "        if key not in self.cache:\n",
    "            #If the cache limit is met get the least relevant in cache then compare current item with least relevant in cache\n",
    "            if len(self.cache) >= self.cache_limit_value:  \n",
    "                least_relevant_term()                                       \n",
    "                if value[\"relevance\"] > least_relevant_value_in_cache:      \n",
    "                    \n",
    "                    #then remove least relevant to make room in cache\n",
    "                    self.remove_least_relevant(least_relevant_key, least_relevant_value_in_cache)          \n",
    "                    \n",
    "                    #Add key and relevance value to minheap list\n",
    "                    minheap_sort(key, value[\"relevance\"])\n",
    "                    \n",
    "                    #Then add key and all tweet elements to cache\n",
    "                    self.cache[key] = value                  \n",
    "        \n",
    "            else:\n",
    "                #Add key and relevance value to minheap list\n",
    "                minheap_sort(key, value[\"relevance\"])\n",
    "                \n",
    "                #Then add key and all tweet elements to cache\n",
    "                self.cache[key] = value\n",
    "        \n",
    "    def remove_least_relevant(self, least_relevant_key, least_relevant_value_in_cache):\n",
    "        \n",
    "        #Remove least relevant from both the cache and the heaped list\n",
    "        self.cache.pop(least_relevant)\n",
    "        heappop(self.minheap, (least_relevant_value_in_cache, least_relevant))\n",
    "        heapify(self.minheap)\n",
    "        \n",
    "    def least_relevant_term(self):\n",
    "        \n",
    "        #Get the least relevant term within the cache as well as key associated with it.      \n",
    "        least_relevant_value_in_cache = self.minheap[0][0]\n",
    "        least_relevant_key = self.minheap[0][1]\n",
    "        return least_relevant_value_in_cache, least_relevant_key\n",
    "    \n",
    "    def minheap_sort(self, key, value):\n",
    "        \n",
    "        #The relevance will be the new key, and the key will be the value in the minheap.      \n",
    "        heappush(self.minheap, (value, key))\n",
    "        heapify(self.minheap)\n",
    "    \n",
    "    def userlist(self, l):\n",
    "        \n",
    "        if l in self.users_through_tweets_cache:\n",
    "            userCounts = self.users_through_tweets_cache[l]\n",
    "            return userCounts.head(5)\n",
    "        \n",
    "        userCounts = l.user.value_counts().to_frame(name = 'relevant_tweets')\n",
    "        userCounts['user_id'] = list(userCounts.index)\n",
    "        \n",
    "        print('u1')\n",
    "        print(time.time())\n",
    "        \n",
    "        query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM users_table \n",
    "        WHERE id IN (%s)\n",
    "        \"\"\" % ', '.join(str(x) for x in userCounts.user_id)\n",
    "        \n",
    "        print('u2')\n",
    "        print(time.time())\n",
    "        \n",
    "        userList = pd.read_sql(query, connection1)\n",
    "        \n",
    "        print('u3')\n",
    "        print(time.time())\n",
    "        \n",
    "        userCounts = userCounts.merge(userList, left_on = 'user_id', right_on = 'id')\n",
    "        \n",
    "        userCounts = userCounts.sort_values(by=['relevant_tweets', 'followers_count', 'friends_count'], ascending = False)\n",
    "        \n",
    "        self.users_through_tweets_cache[l] = userCounts\n",
    "        self.users_through_tweets_list.append(l)\n",
    "        #If the queue is larger than the total accepted searches remove \n",
    "        if len(self.recent_hashtag_searches_cache) > self.total_searches_kept_in_cache:\n",
    "            a = self.users_through_tweets_list.pop(0)\n",
    "            self.users_through_tweets_cache.pop(a)\n",
    "        \n",
    "        print('u4')\n",
    "        print(time.time())\n",
    "        \n",
    "        return userCounts.head(5)\n",
    "    \n",
    "    def keyword(self, word, querytype):\n",
    "        \n",
    "        #Make a blank dictionary\n",
    "        l={}\n",
    "        \n",
    "        #Grab all the tweet ids associated with the word/hashtag\n",
    "        if querytype == \"Text\":\n",
    "            #If word is in searched cache just return that dictionary\n",
    "            if word in self.recent_keyword_searches_cache:\n",
    "                self.recent_keyword_searches.remove(word)\n",
    "                self.recent_keyword_searches.append(word)\n",
    "                l = self.recent_keyword_searches_cache[word]\n",
    "                return pd.DataFrame.from_dict(l).transpose()\n",
    "            else:\n",
    "                ids = self.keyword_tdm[word] #Could use .head(10) to get only the top 10\n",
    "        elif querytype == \"Hashtag\":\n",
    "            #If word is in searched cache just return that dictionary\n",
    "            if word in self.recent_hashtag_searches_cache:\n",
    "                self.recent_hashtag_searches.remove(word)\n",
    "                self.recent_hashtag_searches.append(word)\n",
    "                l = self.recent_hashtag_searches_cache[word]\n",
    "                return pd.DataFrame.from_dict(l).transpose()\n",
    "            else:\n",
    "                ids = self.hashtag_tdm[word]\n",
    "        \n",
    "        #Search through cache first for all tweet ids\n",
    "        #If it's not in the cache find it in the database\n",
    "        for i in ids:\n",
    "            if i in self.cache:\n",
    "                l[i] = self.cache[i]\n",
    "            else:\n",
    "                l[i] = self.connection_name.find({\"id\":i})\n",
    "        \n",
    "        #make a nested dictionary with the three most recent searched words saved in a queue\n",
    "        if querytype == \"Text\":\n",
    "            self.recent_keyword_searches_cache[word] = l\n",
    "            self.recent_keyword_searches.append(word)\n",
    "            #If the queue is larger than the total accepted searches remove \n",
    "            if len(self.recent_keyword_searches_cache) > self.total_searches_kept_in_cache:\n",
    "                a = self.recent_keyword_searches.pop(0)\n",
    "                self.recent_keyword_searches_cache.pop(a)\n",
    "        elif querytype == \"Hashtag\":\n",
    "            self.recent_hashtag_searches_cache[word] = l\n",
    "            self.recent_hashtag_searches.append(word)\n",
    "            #If the queue is larger than the total accepted searches remove \n",
    "            if len(self.recent_hashtag_searches_cache) > self.total_searches_kept_in_cache:\n",
    "                a = self.recent_hashtag_searches.pop(0)\n",
    "                self.recent_hashtag_searches_cache.pop(a)\n",
    "            \n",
    "        l = pd.DataFrame.from_dict(l).transpose()\n",
    "        \n",
    "        #Return a dictionary of all of the ids and associated tweets\n",
    "        return l\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e04682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
